{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 神经网络模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_c2_s0.1_b16_lr0.001_d0.5_e100\n",
      "models/model_sk_c2_s0.1_b16_lr0.001_d0.5_e100.pth\n",
      "True\n",
      "1\n",
      "GeForce MX150\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class Para:\n",
    "    # tensor_board_log_dir = 'runs/exp0'\n",
    "    feature_column_start_name = 'ep_ratio_ttm'\n",
    "    feature_column_end_name = 'BR'\n",
    "\n",
    "    # 模型设置\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classification = 2 # 2, 3\n",
    "\n",
    "    # 权重\n",
    "    cross_weight = list()\n",
    "    if classification == 3:\n",
    "        cross_weight = [1.0, 1.0 ,1.0]\n",
    "    elif classification == 2:\n",
    "        cross_weight = [1.0, 1.0]\n",
    "    elif classification == 5:\n",
    "        cross_weight = [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "    batch_size = 16\n",
    "    lr = 1e-3\n",
    "    drop = 0.5\n",
    "    epochs = 100\n",
    "\n",
    "    # 数据集设置\n",
    "    month_in_sample = range(0, 1)\n",
    "    # month_test = range(36, 48)\n",
    "\n",
    "    percent_cv = 0.1 # 10% cross validation\n",
    "\n",
    "    data_path = 'data/sk_space_1d_rate_20d_17-21_pre'\n",
    "\n",
    "\n",
    "    seed = 2022\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    info_str0 = data_path[5:7]+'_'+'c'+str(classification)+'_s'+str(percent_cv)\n",
    "    info_str1 = '_b'+str(batch_size)+'_lr'+str(lr)+'_d'+str(drop)+'_e'+str(epochs)\n",
    "    info_str = info_str0 + info_str1\n",
    "\n",
    "    save_model_path = 'models/'+'model_'+info_str+'.pth'\n",
    "\n",
    "para = Para()\n",
    "print(para.info_str)\n",
    "print(para.save_model_path)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 构建训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      return_bin order_book_id board_type sector_code  month        date  \\\n0            1.0   600376.XSHG  MainBoard  RealEstate      0  2017-01-03   \n1            1.0   600376.XSHG  MainBoard  RealEstate      1  2017-01-04   \n2            1.0   600376.XSHG  MainBoard  RealEstate      2  2017-01-05   \n3            0.0   600376.XSHG  MainBoard  RealEstate      3  2017-01-06   \n4            1.0   600376.XSHG  MainBoard  RealEstate      4  2017-01-09   \n...          ...           ...        ...         ...    ...         ...   \n1189         0.0   600376.XSHG  MainBoard  RealEstate   1192  2021-11-29   \n1190         0.0   600376.XSHG  MainBoard  RealEstate   1193  2021-11-30   \n1191         0.0   600376.XSHG  MainBoard  RealEstate   1194  2021-12-01   \n1192         0.0   600376.XSHG  MainBoard  RealEstate   1195  2021-12-02   \n1193         0.0   600376.XSHG  MainBoard  RealEstate   1196  2021-12-03   \n\n      yield_rate  ep_ratio_ttm  pb_ratio_ttm  sp_ratio_ttm  ...     RSI10  \\\n0      -0.235758     -1.411342      2.269983     -1.273296  ... -0.176158   \n1      -0.212666     -1.419161      2.312394     -1.280733  ...  0.563332   \n2      -0.012847     -1.415701      2.293545     -1.277441  ...  0.205077   \n3       0.008439     -1.417434      2.302970     -1.279090  ...  0.102341   \n4      -0.054613     -1.420023      2.317107     -1.281552  ...  0.818119   \n...          ...           ...           ...           ...  ...       ...   \n1189    2.146251      1.209308     -1.466971      3.029146  ...  0.019490   \n1190    2.398559      1.232542     -1.478548      3.062748  ... -0.058182   \n1191    2.238078      1.186366     -1.455393      2.995967  ...  0.530404   \n1192    2.176447      1.126572     -1.424521      2.909491  ...  0.998287   \n1193    2.246023      1.156221     -1.439957      2.952370  ...  0.469253   \n\n            SY    BIAS20     VOL30     VOL60    VOL120    VOLT20    VOLT60  \\\n0     1.939393 -0.343228  3.077250  2.097063  2.504830  0.386540  0.343156   \n1     1.939393 -0.123865  3.058393  2.052508  2.496684  0.328454  0.339311   \n2     1.267610 -0.129406  2.845400  2.009023  2.478314  0.140969  0.342943   \n3     1.939393 -0.032727  2.658063  1.981885  2.455540 -0.015838  0.342943   \n4     1.939393  0.093412  2.005796  1.972691  2.419643 -0.342537  0.340627   \n...        ...       ...       ...       ...       ...       ...       ...   \n1189 -0.747738  0.223932 -0.048353 -0.370257 -0.790084 -1.188693 -0.353637   \n1190 -0.747738  0.067898 -0.101384 -0.371908 -0.790859 -1.197434 -0.333250   \n1191 -0.075955  0.357910 -0.112933 -0.373548 -0.786568 -1.193840 -0.319589   \n1192 -0.075955  0.710331 -0.095406 -0.369987 -0.776094 -1.137295 -0.315319   \n1193 -0.075955  0.473663 -0.230882 -0.367559 -0.769096 -1.144598 -0.315042   \n\n            AR        BR  \n0    -0.477163 -1.110336  \n1    -0.623190 -1.059116  \n2    -0.661480 -0.998378  \n3    -0.541901 -0.971592  \n4    -1.345192 -1.570440  \n...        ...       ...  \n1189 -0.928837 -1.234122  \n1190 -0.439751 -0.827627  \n1191 -0.044396 -0.533675  \n1192  0.754954 -0.036107  \n1193  0.834565 -0.100327  \n\n[1194 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>return_bin</th>\n      <th>order_book_id</th>\n      <th>board_type</th>\n      <th>sector_code</th>\n      <th>month</th>\n      <th>date</th>\n      <th>yield_rate</th>\n      <th>ep_ratio_ttm</th>\n      <th>pb_ratio_ttm</th>\n      <th>sp_ratio_ttm</th>\n      <th>...</th>\n      <th>RSI10</th>\n      <th>SY</th>\n      <th>BIAS20</th>\n      <th>VOL30</th>\n      <th>VOL60</th>\n      <th>VOL120</th>\n      <th>VOLT20</th>\n      <th>VOLT60</th>\n      <th>AR</th>\n      <th>BR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>0</td>\n      <td>2017-01-03</td>\n      <td>-0.235758</td>\n      <td>-1.411342</td>\n      <td>2.269983</td>\n      <td>-1.273296</td>\n      <td>...</td>\n      <td>-0.176158</td>\n      <td>1.939393</td>\n      <td>-0.343228</td>\n      <td>3.077250</td>\n      <td>2.097063</td>\n      <td>2.504830</td>\n      <td>0.386540</td>\n      <td>0.343156</td>\n      <td>-0.477163</td>\n      <td>-1.110336</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>1</td>\n      <td>2017-01-04</td>\n      <td>-0.212666</td>\n      <td>-1.419161</td>\n      <td>2.312394</td>\n      <td>-1.280733</td>\n      <td>...</td>\n      <td>0.563332</td>\n      <td>1.939393</td>\n      <td>-0.123865</td>\n      <td>3.058393</td>\n      <td>2.052508</td>\n      <td>2.496684</td>\n      <td>0.328454</td>\n      <td>0.339311</td>\n      <td>-0.623190</td>\n      <td>-1.059116</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>2</td>\n      <td>2017-01-05</td>\n      <td>-0.012847</td>\n      <td>-1.415701</td>\n      <td>2.293545</td>\n      <td>-1.277441</td>\n      <td>...</td>\n      <td>0.205077</td>\n      <td>1.267610</td>\n      <td>-0.129406</td>\n      <td>2.845400</td>\n      <td>2.009023</td>\n      <td>2.478314</td>\n      <td>0.140969</td>\n      <td>0.342943</td>\n      <td>-0.661480</td>\n      <td>-0.998378</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>3</td>\n      <td>2017-01-06</td>\n      <td>0.008439</td>\n      <td>-1.417434</td>\n      <td>2.302970</td>\n      <td>-1.279090</td>\n      <td>...</td>\n      <td>0.102341</td>\n      <td>1.939393</td>\n      <td>-0.032727</td>\n      <td>2.658063</td>\n      <td>1.981885</td>\n      <td>2.455540</td>\n      <td>-0.015838</td>\n      <td>0.342943</td>\n      <td>-0.541901</td>\n      <td>-0.971592</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>4</td>\n      <td>2017-01-09</td>\n      <td>-0.054613</td>\n      <td>-1.420023</td>\n      <td>2.317107</td>\n      <td>-1.281552</td>\n      <td>...</td>\n      <td>0.818119</td>\n      <td>1.939393</td>\n      <td>0.093412</td>\n      <td>2.005796</td>\n      <td>1.972691</td>\n      <td>2.419643</td>\n      <td>-0.342537</td>\n      <td>0.340627</td>\n      <td>-1.345192</td>\n      <td>-1.570440</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1189</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>1192</td>\n      <td>2021-11-29</td>\n      <td>2.146251</td>\n      <td>1.209308</td>\n      <td>-1.466971</td>\n      <td>3.029146</td>\n      <td>...</td>\n      <td>0.019490</td>\n      <td>-0.747738</td>\n      <td>0.223932</td>\n      <td>-0.048353</td>\n      <td>-0.370257</td>\n      <td>-0.790084</td>\n      <td>-1.188693</td>\n      <td>-0.353637</td>\n      <td>-0.928837</td>\n      <td>-1.234122</td>\n    </tr>\n    <tr>\n      <th>1190</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>1193</td>\n      <td>2021-11-30</td>\n      <td>2.398559</td>\n      <td>1.232542</td>\n      <td>-1.478548</td>\n      <td>3.062748</td>\n      <td>...</td>\n      <td>-0.058182</td>\n      <td>-0.747738</td>\n      <td>0.067898</td>\n      <td>-0.101384</td>\n      <td>-0.371908</td>\n      <td>-0.790859</td>\n      <td>-1.197434</td>\n      <td>-0.333250</td>\n      <td>-0.439751</td>\n      <td>-0.827627</td>\n    </tr>\n    <tr>\n      <th>1191</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>1194</td>\n      <td>2021-12-01</td>\n      <td>2.238078</td>\n      <td>1.186366</td>\n      <td>-1.455393</td>\n      <td>2.995967</td>\n      <td>...</td>\n      <td>0.530404</td>\n      <td>-0.075955</td>\n      <td>0.357910</td>\n      <td>-0.112933</td>\n      <td>-0.373548</td>\n      <td>-0.786568</td>\n      <td>-1.193840</td>\n      <td>-0.319589</td>\n      <td>-0.044396</td>\n      <td>-0.533675</td>\n    </tr>\n    <tr>\n      <th>1192</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>1195</td>\n      <td>2021-12-02</td>\n      <td>2.176447</td>\n      <td>1.126572</td>\n      <td>-1.424521</td>\n      <td>2.909491</td>\n      <td>...</td>\n      <td>0.998287</td>\n      <td>-0.075955</td>\n      <td>0.710331</td>\n      <td>-0.095406</td>\n      <td>-0.369987</td>\n      <td>-0.776094</td>\n      <td>-1.137295</td>\n      <td>-0.315319</td>\n      <td>0.754954</td>\n      <td>-0.036107</td>\n    </tr>\n    <tr>\n      <th>1193</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>1196</td>\n      <td>2021-12-03</td>\n      <td>2.246023</td>\n      <td>1.156221</td>\n      <td>-1.439957</td>\n      <td>2.952370</td>\n      <td>...</td>\n      <td>0.469253</td>\n      <td>-0.075955</td>\n      <td>0.473663</td>\n      <td>-0.230882</td>\n      <td>-0.367559</td>\n      <td>-0.769096</td>\n      <td>-1.144598</td>\n      <td>-0.315042</td>\n      <td>0.834565</td>\n      <td>-0.100327</td>\n    </tr>\n  </tbody>\n</table>\n<p>1194 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_in_sample = None\n",
    "for i_month in para.month_in_sample:\n",
    "    file_name = para.data_path + '/' + str(i_month) + '.csv'\n",
    "    data_curr_month = pd.read_csv(file_name)\n",
    "\n",
    "    data_curr_month = data_curr_month.dropna(axis=0)\n",
    "\n",
    "    data_curr_month.insert(loc=0, column='return_bin', value=np.nan)\n",
    "\n",
    "    data_curr_month.loc[data_curr_month['yield_rate']>0, 'return_bin'] = 0\n",
    "    data_curr_month.loc[data_curr_month['yield_rate']<=0, 'return_bin'] = 1\n",
    "\n",
    "    if i_month == para.month_in_sample[0]:\n",
    "        data_in_sample = data_curr_month\n",
    "    else:\n",
    "        data_in_sample = pd.concat([data_in_sample, data_curr_month])\n",
    "        # data_in_sample = data_in_sample.append(data_curr_month)\n",
    "\n",
    "data_in_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      ep_ratio_ttm  pb_ratio_ttm  sp_ratio_ttm  MACD_DIFF  MACD_DEA  \\\n0        -1.411342      2.269983     -1.273296  -1.025096 -0.866096   \n1        -1.419161      2.312394     -1.280733  -0.923666 -0.893492   \n2        -1.415701      2.293545     -1.277441  -0.852875 -0.900033   \n3        -1.417434      2.302970     -1.279090  -0.774502 -0.888245   \n4        -1.420023      2.317107     -1.281552  -0.685683 -0.859525   \n...            ...           ...           ...        ...       ...   \n1069      0.865492     -1.035077      1.289191  -0.005168 -0.109375   \n1070      0.848154     -1.023156      1.270623   0.035801 -0.079734   \n1071      0.853913     -1.027130      1.276791   0.064486 -0.049791   \n1072      0.871313     -1.039051      1.295425   0.072421 -0.024114   \n1073      0.859693     -1.031103      1.282980   0.091003  0.000464   \n\n      MACD_HIST     RSI10        SY    BIAS20     VOL30     VOL60    VOL120  \\\n0     -0.652229 -0.176158  1.939393 -0.343228  3.077250  2.097063  2.504830   \n1     -0.290177  0.563332  1.939393 -0.123865  3.058393  2.052508  2.496684   \n2     -0.070599  0.205077  1.267610 -0.129406  2.845400  2.009023  2.478314   \n3      0.122402  0.102341  1.939393 -0.032727  2.658063  1.981885  2.455540   \n4      0.300690  0.818119  1.939393  0.093412  2.005796  1.972691  2.419643   \n...         ...       ...       ...       ...       ...       ...       ...   \n1069   0.271298  1.026958 -0.075955  0.431593 -0.109275 -0.466151 -0.773933   \n1070   0.310384  1.090179  0.595827  0.504560 -0.328337 -0.474823 -0.773665   \n1071   0.313559  1.090179 -0.075955  0.411834 -0.432338 -0.500946 -0.774325   \n1072   0.268650  0.497477 -0.075955  0.240095 -0.522253 -0.522041 -0.776736   \n1073   0.257071  0.652708 -0.075955  0.288732 -0.565593 -0.533050 -0.775647   \n\n        VOLT20    VOLT60        AR        BR  \n0     0.386540  0.343156 -0.477163 -1.110336  \n1     0.328454  0.339311 -0.623190 -1.059116  \n2     0.140969  0.342943 -0.661480 -0.998378  \n3    -0.015838  0.342943 -0.541901 -0.971592  \n4    -0.342537  0.340627 -1.345192 -1.570440  \n...        ...       ...       ...       ...  \n1069 -0.969268 -0.918862 -0.714858 -0.785255  \n1070 -0.990972 -0.924201 -0.401836 -0.627900  \n1071 -1.052036 -0.927824 -0.324829 -0.482743  \n1072 -1.180918 -0.933460 -0.261731 -0.653516  \n1073 -1.222433 -0.945410 -0.359947 -0.760148  \n\n[1074 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ep_ratio_ttm</th>\n      <th>pb_ratio_ttm</th>\n      <th>sp_ratio_ttm</th>\n      <th>MACD_DIFF</th>\n      <th>MACD_DEA</th>\n      <th>MACD_HIST</th>\n      <th>RSI10</th>\n      <th>SY</th>\n      <th>BIAS20</th>\n      <th>VOL30</th>\n      <th>VOL60</th>\n      <th>VOL120</th>\n      <th>VOLT20</th>\n      <th>VOLT60</th>\n      <th>AR</th>\n      <th>BR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.411342</td>\n      <td>2.269983</td>\n      <td>-1.273296</td>\n      <td>-1.025096</td>\n      <td>-0.866096</td>\n      <td>-0.652229</td>\n      <td>-0.176158</td>\n      <td>1.939393</td>\n      <td>-0.343228</td>\n      <td>3.077250</td>\n      <td>2.097063</td>\n      <td>2.504830</td>\n      <td>0.386540</td>\n      <td>0.343156</td>\n      <td>-0.477163</td>\n      <td>-1.110336</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.419161</td>\n      <td>2.312394</td>\n      <td>-1.280733</td>\n      <td>-0.923666</td>\n      <td>-0.893492</td>\n      <td>-0.290177</td>\n      <td>0.563332</td>\n      <td>1.939393</td>\n      <td>-0.123865</td>\n      <td>3.058393</td>\n      <td>2.052508</td>\n      <td>2.496684</td>\n      <td>0.328454</td>\n      <td>0.339311</td>\n      <td>-0.623190</td>\n      <td>-1.059116</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.415701</td>\n      <td>2.293545</td>\n      <td>-1.277441</td>\n      <td>-0.852875</td>\n      <td>-0.900033</td>\n      <td>-0.070599</td>\n      <td>0.205077</td>\n      <td>1.267610</td>\n      <td>-0.129406</td>\n      <td>2.845400</td>\n      <td>2.009023</td>\n      <td>2.478314</td>\n      <td>0.140969</td>\n      <td>0.342943</td>\n      <td>-0.661480</td>\n      <td>-0.998378</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.417434</td>\n      <td>2.302970</td>\n      <td>-1.279090</td>\n      <td>-0.774502</td>\n      <td>-0.888245</td>\n      <td>0.122402</td>\n      <td>0.102341</td>\n      <td>1.939393</td>\n      <td>-0.032727</td>\n      <td>2.658063</td>\n      <td>1.981885</td>\n      <td>2.455540</td>\n      <td>-0.015838</td>\n      <td>0.342943</td>\n      <td>-0.541901</td>\n      <td>-0.971592</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.420023</td>\n      <td>2.317107</td>\n      <td>-1.281552</td>\n      <td>-0.685683</td>\n      <td>-0.859525</td>\n      <td>0.300690</td>\n      <td>0.818119</td>\n      <td>1.939393</td>\n      <td>0.093412</td>\n      <td>2.005796</td>\n      <td>1.972691</td>\n      <td>2.419643</td>\n      <td>-0.342537</td>\n      <td>0.340627</td>\n      <td>-1.345192</td>\n      <td>-1.570440</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.865492</td>\n      <td>-1.035077</td>\n      <td>1.289191</td>\n      <td>-0.005168</td>\n      <td>-0.109375</td>\n      <td>0.271298</td>\n      <td>1.026958</td>\n      <td>-0.075955</td>\n      <td>0.431593</td>\n      <td>-0.109275</td>\n      <td>-0.466151</td>\n      <td>-0.773933</td>\n      <td>-0.969268</td>\n      <td>-0.918862</td>\n      <td>-0.714858</td>\n      <td>-0.785255</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.848154</td>\n      <td>-1.023156</td>\n      <td>1.270623</td>\n      <td>0.035801</td>\n      <td>-0.079734</td>\n      <td>0.310384</td>\n      <td>1.090179</td>\n      <td>0.595827</td>\n      <td>0.504560</td>\n      <td>-0.328337</td>\n      <td>-0.474823</td>\n      <td>-0.773665</td>\n      <td>-0.990972</td>\n      <td>-0.924201</td>\n      <td>-0.401836</td>\n      <td>-0.627900</td>\n    </tr>\n    <tr>\n      <th>1071</th>\n      <td>0.853913</td>\n      <td>-1.027130</td>\n      <td>1.276791</td>\n      <td>0.064486</td>\n      <td>-0.049791</td>\n      <td>0.313559</td>\n      <td>1.090179</td>\n      <td>-0.075955</td>\n      <td>0.411834</td>\n      <td>-0.432338</td>\n      <td>-0.500946</td>\n      <td>-0.774325</td>\n      <td>-1.052036</td>\n      <td>-0.927824</td>\n      <td>-0.324829</td>\n      <td>-0.482743</td>\n    </tr>\n    <tr>\n      <th>1072</th>\n      <td>0.871313</td>\n      <td>-1.039051</td>\n      <td>1.295425</td>\n      <td>0.072421</td>\n      <td>-0.024114</td>\n      <td>0.268650</td>\n      <td>0.497477</td>\n      <td>-0.075955</td>\n      <td>0.240095</td>\n      <td>-0.522253</td>\n      <td>-0.522041</td>\n      <td>-0.776736</td>\n      <td>-1.180918</td>\n      <td>-0.933460</td>\n      <td>-0.261731</td>\n      <td>-0.653516</td>\n    </tr>\n    <tr>\n      <th>1073</th>\n      <td>0.859693</td>\n      <td>-1.031103</td>\n      <td>1.282980</td>\n      <td>0.091003</td>\n      <td>0.000464</td>\n      <td>0.257071</td>\n      <td>0.652708</td>\n      <td>-0.075955</td>\n      <td>0.288732</td>\n      <td>-0.565593</td>\n      <td>-0.533050</td>\n      <td>-0.775647</td>\n      <td>-1.222433</td>\n      <td>-0.945410</td>\n      <td>-0.359947</td>\n      <td>-0.760148</td>\n    </tr>\n  </tbody>\n</table>\n<p>1074 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_in_sample = data_in_sample.loc[:, para.feature_column_start_name: para.feature_column_end_name]\n",
    "y_in_sample = data_in_sample.loc[:, 'return_bin']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_in_sample, y_in_sample, test_size=para.percent_cv, shuffle=False) # True, random_state=para.seed)\n",
    "# X_train, X_cv, y_train, y_cv = train_test_split(X_in_sample, y_in_sample, test_size=para.percent_cv, shuffle=False)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       1.0\n1       1.0\n2       1.0\n3       0.0\n4       1.0\n       ... \n1069    1.0\n1070    1.0\n1071    1.0\n1072    0.0\n1073    1.0\nName: return_bin, Length: 1074, dtype: float64"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      ep_ratio_ttm  pb_ratio_ttm  sp_ratio_ttm  MACD_DIFF  MACD_DEA  \\\n0        -1.411342      2.269983     -1.273296  -1.025096 -0.866096   \n1        -1.419161      2.312394     -1.280733  -0.923666 -0.893492   \n2        -1.415701      2.293545     -1.277441  -0.852875 -0.900033   \n3        -1.417434      2.302970     -1.279090  -0.774502 -0.888245   \n4        -1.420023      2.317107     -1.281552  -0.685683 -0.859525   \n...            ...           ...           ...        ...       ...   \n1069      0.865492     -1.035077      1.289191  -0.005168 -0.109375   \n1070      0.848154     -1.023156      1.270623   0.035801 -0.079734   \n1071      0.853913     -1.027130      1.276791   0.064486 -0.049791   \n1072      0.871313     -1.039051      1.295425   0.072421 -0.024114   \n1073      0.859693     -1.031103      1.282980   0.091003  0.000464   \n\n      MACD_HIST     RSI10        SY    BIAS20     VOL30     VOL60    VOL120  \\\n0     -0.652229 -0.176158  1.939393 -0.343228  3.077250  2.097063  2.504830   \n1     -0.290177  0.563332  1.939393 -0.123865  3.058393  2.052508  2.496684   \n2     -0.070599  0.205077  1.267610 -0.129406  2.845400  2.009023  2.478314   \n3      0.122402  0.102341  1.939393 -0.032727  2.658063  1.981885  2.455540   \n4      0.300690  0.818119  1.939393  0.093412  2.005796  1.972691  2.419643   \n...         ...       ...       ...       ...       ...       ...       ...   \n1069   0.271298  1.026958 -0.075955  0.431593 -0.109275 -0.466151 -0.773933   \n1070   0.310384  1.090179  0.595827  0.504560 -0.328337 -0.474823 -0.773665   \n1071   0.313559  1.090179 -0.075955  0.411834 -0.432338 -0.500946 -0.774325   \n1072   0.268650  0.497477 -0.075955  0.240095 -0.522253 -0.522041 -0.776736   \n1073   0.257071  0.652708 -0.075955  0.288732 -0.565593 -0.533050 -0.775647   \n\n        VOLT20    VOLT60        AR        BR  return_bin  \n0     0.386540  0.343156 -0.477163 -1.110336         1.0  \n1     0.328454  0.339311 -0.623190 -1.059116         1.0  \n2     0.140969  0.342943 -0.661480 -0.998378         1.0  \n3    -0.015838  0.342943 -0.541901 -0.971592         0.0  \n4    -0.342537  0.340627 -1.345192 -1.570440         1.0  \n...        ...       ...       ...       ...         ...  \n1069 -0.969268 -0.918862 -0.714858 -0.785255         1.0  \n1070 -0.990972 -0.924201 -0.401836 -0.627900         1.0  \n1071 -1.052036 -0.927824 -0.324829 -0.482743         1.0  \n1072 -1.180918 -0.933460 -0.261731 -0.653516         0.0  \n1073 -1.222433 -0.945410 -0.359947 -0.760148         1.0  \n\n[1074 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ep_ratio_ttm</th>\n      <th>pb_ratio_ttm</th>\n      <th>sp_ratio_ttm</th>\n      <th>MACD_DIFF</th>\n      <th>MACD_DEA</th>\n      <th>MACD_HIST</th>\n      <th>RSI10</th>\n      <th>SY</th>\n      <th>BIAS20</th>\n      <th>VOL30</th>\n      <th>VOL60</th>\n      <th>VOL120</th>\n      <th>VOLT20</th>\n      <th>VOLT60</th>\n      <th>AR</th>\n      <th>BR</th>\n      <th>return_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.411342</td>\n      <td>2.269983</td>\n      <td>-1.273296</td>\n      <td>-1.025096</td>\n      <td>-0.866096</td>\n      <td>-0.652229</td>\n      <td>-0.176158</td>\n      <td>1.939393</td>\n      <td>-0.343228</td>\n      <td>3.077250</td>\n      <td>2.097063</td>\n      <td>2.504830</td>\n      <td>0.386540</td>\n      <td>0.343156</td>\n      <td>-0.477163</td>\n      <td>-1.110336</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.419161</td>\n      <td>2.312394</td>\n      <td>-1.280733</td>\n      <td>-0.923666</td>\n      <td>-0.893492</td>\n      <td>-0.290177</td>\n      <td>0.563332</td>\n      <td>1.939393</td>\n      <td>-0.123865</td>\n      <td>3.058393</td>\n      <td>2.052508</td>\n      <td>2.496684</td>\n      <td>0.328454</td>\n      <td>0.339311</td>\n      <td>-0.623190</td>\n      <td>-1.059116</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.415701</td>\n      <td>2.293545</td>\n      <td>-1.277441</td>\n      <td>-0.852875</td>\n      <td>-0.900033</td>\n      <td>-0.070599</td>\n      <td>0.205077</td>\n      <td>1.267610</td>\n      <td>-0.129406</td>\n      <td>2.845400</td>\n      <td>2.009023</td>\n      <td>2.478314</td>\n      <td>0.140969</td>\n      <td>0.342943</td>\n      <td>-0.661480</td>\n      <td>-0.998378</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.417434</td>\n      <td>2.302970</td>\n      <td>-1.279090</td>\n      <td>-0.774502</td>\n      <td>-0.888245</td>\n      <td>0.122402</td>\n      <td>0.102341</td>\n      <td>1.939393</td>\n      <td>-0.032727</td>\n      <td>2.658063</td>\n      <td>1.981885</td>\n      <td>2.455540</td>\n      <td>-0.015838</td>\n      <td>0.342943</td>\n      <td>-0.541901</td>\n      <td>-0.971592</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.420023</td>\n      <td>2.317107</td>\n      <td>-1.281552</td>\n      <td>-0.685683</td>\n      <td>-0.859525</td>\n      <td>0.300690</td>\n      <td>0.818119</td>\n      <td>1.939393</td>\n      <td>0.093412</td>\n      <td>2.005796</td>\n      <td>1.972691</td>\n      <td>2.419643</td>\n      <td>-0.342537</td>\n      <td>0.340627</td>\n      <td>-1.345192</td>\n      <td>-1.570440</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.865492</td>\n      <td>-1.035077</td>\n      <td>1.289191</td>\n      <td>-0.005168</td>\n      <td>-0.109375</td>\n      <td>0.271298</td>\n      <td>1.026958</td>\n      <td>-0.075955</td>\n      <td>0.431593</td>\n      <td>-0.109275</td>\n      <td>-0.466151</td>\n      <td>-0.773933</td>\n      <td>-0.969268</td>\n      <td>-0.918862</td>\n      <td>-0.714858</td>\n      <td>-0.785255</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.848154</td>\n      <td>-1.023156</td>\n      <td>1.270623</td>\n      <td>0.035801</td>\n      <td>-0.079734</td>\n      <td>0.310384</td>\n      <td>1.090179</td>\n      <td>0.595827</td>\n      <td>0.504560</td>\n      <td>-0.328337</td>\n      <td>-0.474823</td>\n      <td>-0.773665</td>\n      <td>-0.990972</td>\n      <td>-0.924201</td>\n      <td>-0.401836</td>\n      <td>-0.627900</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1071</th>\n      <td>0.853913</td>\n      <td>-1.027130</td>\n      <td>1.276791</td>\n      <td>0.064486</td>\n      <td>-0.049791</td>\n      <td>0.313559</td>\n      <td>1.090179</td>\n      <td>-0.075955</td>\n      <td>0.411834</td>\n      <td>-0.432338</td>\n      <td>-0.500946</td>\n      <td>-0.774325</td>\n      <td>-1.052036</td>\n      <td>-0.927824</td>\n      <td>-0.324829</td>\n      <td>-0.482743</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1072</th>\n      <td>0.871313</td>\n      <td>-1.039051</td>\n      <td>1.295425</td>\n      <td>0.072421</td>\n      <td>-0.024114</td>\n      <td>0.268650</td>\n      <td>0.497477</td>\n      <td>-0.075955</td>\n      <td>0.240095</td>\n      <td>-0.522253</td>\n      <td>-0.522041</td>\n      <td>-0.776736</td>\n      <td>-1.180918</td>\n      <td>-0.933460</td>\n      <td>-0.261731</td>\n      <td>-0.653516</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1073</th>\n      <td>0.859693</td>\n      <td>-1.031103</td>\n      <td>1.282980</td>\n      <td>0.091003</td>\n      <td>0.000464</td>\n      <td>0.257071</td>\n      <td>0.652708</td>\n      <td>-0.075955</td>\n      <td>0.288732</td>\n      <td>-0.565593</td>\n      <td>-0.533050</td>\n      <td>-0.775647</td>\n      <td>-1.222433</td>\n      <td>-0.945410</td>\n      <td>-0.359947</td>\n      <td>-0.760148</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1074 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "data_cv = pd.concat([X_cv, y_cv], axis=1)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "\n",
    "X_train_ndarray = X_train.values\n",
    "y_train_ndarray = y_train.values\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train_ndarray).type(torch.FloatTensor), torch.from_numpy(y_train_ndarray).type(torch.LongTensor))\n",
    "\n",
    "# for X_train_temp, y_train_temp in train_dataset:\n",
    "#     print(X_train_temp, y_train_temp)\n",
    "#     print(X_train_temp.dtype, y_train_temp.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_cv_ndarray = X_cv.values\n",
    "y_cv_ndarray = y_cv.values\n",
    "\n",
    "cv_dataset = TensorDataset(torch.from_numpy(X_cv_ndarray).type(torch.FloatTensor), torch.from_numpy(y_cv.values).type(torch.LongTensor))\n",
    "\n",
    "# for X_cv_temp, y_cv_temp in cv_dataset:\n",
    "#     print(X_cv_temp, y_cv_temp)\n",
    "#     print(X_cv_temp.dtype, y_cv_temp.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=para.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "cv_dataloader = DataLoader(\n",
    "    dataset=cv_dataset,\n",
    "    batch_size=para.batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 构建测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data_test = None\n",
    "# for i_month in para.month_test:\n",
    "#\n",
    "#     file_name = para.data_path + '/' + str(i_month) + '.csv'\n",
    "#     data_curr_month = pd.read_csv(file_name)\n",
    "#\n",
    "#     data_curr_month = data_curr_month.dropna(axis=0)\n",
    "#\n",
    "#     data_curr_month = label_data(data=data_curr_month, percent_select=para.percent_select)\n",
    "#\n",
    "#     if i_month == para.month_test[0]:\n",
    "#         data_test = data_curr_month\n",
    "#     else:\n",
    "#         data_test = pd.concat([data_test, data_curr_month])\n",
    "#         # data_test = data_test.append(data_curr_month)\n",
    "#\n",
    "# X_test = data_test.loc[:, para.feature_column_start_name: para.feature_column_end_name]\n",
    "# y_test = data_test.loc[:, 'return_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import TensorDataset\n",
    "# import torch\n",
    "#\n",
    "#\n",
    "# X_test_ndarray = X_test.values\n",
    "# y_test_ndarray = y_test.values\n",
    "#\n",
    "# test_dataset = TensorDataset(torch.from_numpy(X_test_ndarray).type(torch.FloatTensor), torch.from_numpy(y_test_ndarray).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "#\n",
    "#\n",
    "# test_dataloader = DataLoader(\n",
    "#     dataset=test_dataset,\n",
    "#     batch_size=para.batch_size,\n",
    "#     shuffle=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from my_utils.model_class import MLP\n",
    "\n",
    "model = MLP(in_nums=len(X_train.columns), out_nums=para.classification, drop_p=para.drop)\n",
    "# to device\n",
    "model = model.to(device=para.device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, correct = 0, 0\n",
    "\n",
    "    # initialize metric\n",
    "    train_precision = torchmetrics.Precision(average='none', num_classes=para.classification).to(device=para.device)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # to device\n",
    "        X = X.to(device=para.device)\n",
    "        y = y.to(device=para.device)\n",
    "\n",
    "        # compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # metric on current batch\n",
    "        train_precision(pred.argmax(1), y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 10 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Train Error: \\n    Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "    # metric on all batches using custom accumulation\n",
    "    total_precision = train_precision.compute()\n",
    "    print(\"Precision of every train dataset class: \", total_precision)\n",
    "    print()\n",
    "\n",
    "    return correct, train_loss, total_precision\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # initialize metric\n",
    "    test_precision = torchmetrics.Precision(average='none', num_classes=para.classification).to(device=para.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            # to device\n",
    "            X = X.to(device=para.device)\n",
    "            y = y.to(device=para.device)\n",
    "\n",
    "            # compute prediction and loss\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            # metric on current batch\n",
    "            test_precision(pred.argmax(1), y)\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n    Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    # metric on all batches using custom accumulation\n",
    "    total_precision = test_precision.compute()\n",
    "    print(\"Precision of every test dataset class: \", total_precision)\n",
    "    print()\n",
    "\n",
    "    return correct, test_loss, total_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def select_df_to_dataloader(df: pd.DataFrame, select: int) -> DataLoader:\n",
    "\n",
    "    df = df[df['return_bin'] == select]\n",
    "\n",
    "    df_dataset = TensorDataset(\n",
    "        torch.from_numpy(df.loc[:, para.feature_column_start_name: para.feature_column_end_name].values).type(torch.FloatTensor),\n",
    "        torch.from_numpy(df.loc[:, 'return_bin'].values).type(torch.LongTensor))\n",
    "\n",
    "    df_dataloader = DataLoader(\n",
    "        dataset=df_dataset,\n",
    "        batch_size=para.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return df_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# temp2_dataloader = select_df_to_dataloader(df=data_cv, select=2)\n",
    "temp1_dataloader = select_df_to_dataloader(df=data_cv, select=1)\n",
    "temp0_dataloader = select_df_to_dataloader(df=data_cv, select=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 52.9%, Avg loss: 0.691103 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.5143, 0.5370], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 56.7%, Avg loss: 0.683918 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5395, 0.6136], device='cuda:0')\n",
      "\n",
      "Time cost = 1.108734s\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 55.4%, Avg loss: 0.684770 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.5549, 0.5536], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 70.0%, Avg loss: 0.681456 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7391, 0.6757], device='cuda:0')\n",
      "\n",
      "Time cost = 2.079138s\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 54.7%, Avg loss: 0.686226 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.5452, 0.5472], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 73.3%, Avg loss: 0.676872 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8611, 0.6786], device='cuda:0')\n",
      "\n",
      "Time cost = 2.867032s\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 53.5%, Avg loss: 0.685076 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.5253, 0.5404], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 73.3%, Avg loss: 0.675454 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8824, 0.6744], device='cuda:0')\n",
      "\n",
      "Time cost = 3.457453s\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 55.0%, Avg loss: 0.682983 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.5462, 0.5524], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 74.2%, Avg loss: 0.675231 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.9091, 0.6782], device='cuda:0')\n",
      "\n",
      "Time cost = 4.062248s\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 56.9%, Avg loss: 0.673118 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.5780, 0.5646], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 74.2%, Avg loss: 0.670103 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.9091, 0.6782], device='cuda:0')\n",
      "\n",
      "Time cost = 4.766754s\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 58.0%, Avg loss: 0.671818 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.5829, 0.5784], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.668961 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8684, 0.6951], device='cuda:0')\n",
      "\n",
      "Time cost = 5.541372s\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 60.1%, Avg loss: 0.667716 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6073, 0.5964], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.664050 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.6905], device='cuda:0')\n",
      "\n",
      "Time cost = 6.113383s\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 58.1%, Avg loss: 0.670684 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.5875, 0.5774], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.8%, Avg loss: 0.667138 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8919, 0.6988], device='cuda:0')\n",
      "\n",
      "Time cost = 6.667284s\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 59.7%, Avg loss: 0.655914 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6135, 0.5881], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 73.3%, Avg loss: 0.663951 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.6829], device='cuda:0')\n",
      "\n",
      "Time cost = 7.220600s\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 61.0%, Avg loss: 0.653309 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6332, 0.5977], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.8%, Avg loss: 0.659968 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8718, 0.7037], device='cuda:0')\n",
      "\n",
      "Time cost = 7.814590s\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 60.5%, Avg loss: 0.657539 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6310, 0.5925], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.657276 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.6905], device='cuda:0')\n",
      "\n",
      "Time cost = 8.374961s\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 62.6%, Avg loss: 0.640718 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6737, 0.6043], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.667530 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.6905], device='cuda:0')\n",
      "\n",
      "Time cost = 8.920633s\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 61.6%, Avg loss: 0.641120 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6496, 0.6003], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 74.2%, Avg loss: 0.662575 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8000, 0.7067], device='cuda:0')\n",
      "\n",
      "Time cost = 9.466528s\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 59.8%, Avg loss: 0.652339 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6121, 0.5899], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 62.5%, Avg loss: 0.671656 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.6032, 0.6491], device='cuda:0')\n",
      "\n",
      "Time cost = 10.021302s\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 62.1%, Avg loss: 0.656275 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6455, 0.6078], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.674520 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5135, 0.5652], device='cuda:0')\n",
      "\n",
      "Time cost = 10.574923s\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 61.3%, Avg loss: 0.643642 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6499, 0.5957], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.674652 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5455], device='cuda:0')\n",
      "\n",
      "Time cost = 11.228980s\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 61.7%, Avg loss: 0.638205 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6402, 0.6049], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 61.7%, Avg loss: 0.667350 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5938, 0.6429], device='cuda:0')\n",
      "\n",
      "Time cost = 11.926216s\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 62.1%, Avg loss: 0.642612 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6608, 0.6025], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 65.8%, Avg loss: 0.668744 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.6441, 0.6721], device='cuda:0')\n",
      "\n",
      "Time cost = 12.475957s\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.0%, Avg loss: 0.631518 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6890, 0.6291], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 59.2%, Avg loss: 0.667519 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5672, 0.6226], device='cuda:0')\n",
      "\n",
      "Time cost = 13.029459s\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 62.8%, Avg loss: 0.627609 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6568, 0.6120], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.672520 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5063, 0.5610], device='cuda:0')\n",
      "\n",
      "Time cost = 13.581791s\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 61.7%, Avg loss: 0.625915 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6456, 0.6028], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 49.2%, Avg loss: 0.676251 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4828, 0.5152], device='cuda:0')\n",
      "\n",
      "Time cost = 14.123018s\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 63.5%, Avg loss: 0.624318 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6649, 0.6187], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.671568 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5063, 0.5610], device='cuda:0')\n",
      "\n",
      "Time cost = 14.681410s\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.5%, Avg loss: 0.614675 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6901, 0.6348], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.670865 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5556], device='cuda:0')\n",
      "\n",
      "Time cost = 15.244654s\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.2%, Avg loss: 0.634052 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7147, 0.6235], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 49.2%, Avg loss: 0.669155 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4824, 0.5143], device='cuda:0')\n",
      "\n",
      "Time cost = 15.796671s\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.5%, Avg loss: 0.615325 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7039, 0.6299], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 49.2%, Avg loss: 0.669200 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4842, 0.5200], device='cuda:0')\n",
      "\n",
      "Time cost = 16.351355s\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.0%, Avg loss: 0.617382 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6785, 0.6333], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 47.5%, Avg loss: 0.677818 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4752, 0.4737], device='cuda:0')\n",
      "\n",
      "Time cost = 16.999699s\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 64.2%, Avg loss: 0.626106 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6895, 0.6196], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.668725 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4945, 0.5517], device='cuda:0')\n",
      "\n",
      "Time cost = 17.698486s\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 63.3%, Avg loss: 0.619319 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6904, 0.6085], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 49.2%, Avg loss: 0.670493 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4845, 0.5217], device='cuda:0')\n",
      "\n",
      "Time cost = 18.291692s\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.9%, Avg loss: 0.600142 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6892, 0.6415], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 46.7%, Avg loss: 0.678106 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4700, 0.4500], device='cuda:0')\n",
      "\n",
      "Time cost = 18.917056s\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.4%, Avg loss: 0.610796 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6903, 0.6335], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 49.2%, Avg loss: 0.664894 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4845, 0.5217], device='cuda:0')\n",
      "\n",
      "Time cost = 19.575298s\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 64.2%, Avg loss: 0.616318 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6833, 0.6204], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 47.5%, Avg loss: 0.671918 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4747, 0.4762], device='cuda:0')\n",
      "\n",
      "Time cost = 20.264035s\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 66.9%, Avg loss: 0.601265 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7230, 0.6410], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 48.3%, Avg loss: 0.682215 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4804, 0.5000], device='cuda:0')\n",
      "\n",
      "Time cost = 20.923273s\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.4%, Avg loss: 0.595044 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7126, 0.6262], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 48.3%, Avg loss: 0.671351 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4796, 0.5000], device='cuda:0')\n",
      "\n",
      "Time cost = 21.465137s\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.9%, Avg loss: 0.602650 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7176, 0.6314], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 47.5%, Avg loss: 0.677668 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4757, 0.4706], device='cuda:0')\n",
      "\n",
      "Time cost = 22.025705s\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.1%, Avg loss: 0.602259 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6888, 0.6304], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 46.7%, Avg loss: 0.687391 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4712, 0.4375], device='cuda:0')\n",
      "\n",
      "Time cost = 22.584041s\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 66.3%, Avg loss: 0.590630 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7013, 0.6415], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.685547 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.7000], device='cuda:0')\n",
      "\n",
      "Time cost = 23.189447s\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.9%, Avg loss: 0.603261 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7129, 0.6582], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.686925 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.7000], device='cuda:0')\n",
      "\n",
      "Time cost = 23.879601s\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.7%, Avg loss: 0.576843 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6867, 0.6400], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.670009 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.7000], device='cuda:0')\n",
      "\n",
      "Time cost = 24.491023s\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.4%, Avg loss: 0.589390 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7434, 0.6416], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.669567 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 25.100669s\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.5%, Avg loss: 0.581924 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7199, 0.6503], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.0%, Avg loss: 0.679380 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4904, 0.5625], device='cuda:0')\n",
      "\n",
      "Time cost = 25.671496s\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 68.0%, Avg loss: 0.585163 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7212, 0.6559], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.0%, Avg loss: 0.667901 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4902, 0.5556], device='cuda:0')\n",
      "\n",
      "Time cost = 26.255686s\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.3%, Avg loss: 0.572789 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7219, 0.6471], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.672380 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4951, 0.5882], device='cuda:0')\n",
      "\n",
      "Time cost = 26.893123s\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.2%, Avg loss: 0.577921 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7078, 0.6514], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.657806 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4950, 0.5789], device='cuda:0')\n",
      "\n",
      "Time cost = 27.507824s\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 69.5%, Avg loss: 0.564234 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7467, 0.6657], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.684409 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6429], device='cuda:0')\n",
      "\n",
      "Time cost = 28.118849s\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 68.2%, Avg loss: 0.579926 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7431, 0.6517], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.676545 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5093, 0.7500], device='cuda:0')\n",
      "\n",
      "Time cost = 28.722379s\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 66.9%, Avg loss: 0.572852 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7411, 0.6369], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.670081 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5100, 0.6500], device='cuda:0')\n",
      "\n",
      "Time cost = 29.383962s\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 69.4%, Avg loss: 0.570458 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7582, 0.6606], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.673579 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4951, 0.5882], device='cuda:0')\n",
      "\n",
      "Time cost = 30.084887s\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.2%, Avg loss: 0.580938 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7298, 0.6434], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.664043 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4948, 0.5652], device='cuda:0')\n",
      "\n",
      "Time cost = 30.795322s\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 68.1%, Avg loss: 0.562800 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7574, 0.6454], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.669232 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5100, 0.6500], device='cuda:0')\n",
      "\n",
      "Time cost = 31.539337s\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 68.7%, Avg loss: 0.572653 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7507, 0.6550], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.662643 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4947, 0.5600], device='cuda:0')\n",
      "\n",
      "Time cost = 32.107066s\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.7%, Avg loss: 0.577571 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7471, 0.6438], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.652175 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4947, 0.5600], device='cuda:0')\n",
      "\n",
      "Time cost = 32.673715s\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.1%, Avg loss: 0.561022 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7692, 0.6662], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 54.2%, Avg loss: 0.662056 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5146, 0.7059], device='cuda:0')\n",
      "\n",
      "Time cost = 33.229228s\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.0%, Avg loss: 0.550038 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7814, 0.6737], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 54.2%, Avg loss: 0.673111 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5146, 0.7059], device='cuda:0')\n",
      "\n",
      "Time cost = 33.772760s\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.1%, Avg loss: 0.563355 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7440, 0.6382], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 54.2%, Avg loss: 0.698485 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5140, 0.7692], device='cuda:0')\n",
      "\n",
      "Time cost = 34.312868s\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.3%, Avg loss: 0.558105 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7450, 0.6776], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.687109 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6429], device='cuda:0')\n",
      "\n",
      "Time cost = 34.859082s\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 68.3%, Avg loss: 0.559520 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7263, 0.6589], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.691106 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5093, 0.7500], device='cuda:0')\n",
      "\n",
      "Time cost = 35.503358s\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.3%, Avg loss: 0.542980 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7676, 0.6690], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.702686 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6429], device='cuda:0')\n",
      "\n",
      "Time cost = 36.164503s\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 68.0%, Avg loss: 0.577063 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7224, 0.6555], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.697958 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6429], device='cuda:0')\n",
      "\n",
      "Time cost = 36.717192s\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 69.2%, Avg loss: 0.556377 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7487, 0.6614], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 54.2%, Avg loss: 0.681349 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5146, 0.7059], device='cuda:0')\n",
      "\n",
      "Time cost = 37.273181s\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 68.5%, Avg loss: 0.555408 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7289, 0.6603], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.684424 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6429], device='cuda:0')\n",
      "\n",
      "Time cost = 37.853596s\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.9%, Avg loss: 0.528911 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7690, 0.6768], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.698206 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6429], device='cuda:0')\n",
      "\n",
      "Time cost = 38.409372s\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.9%, Avg loss: 0.556317 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7778, 0.6738], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.711744 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6667], device='cuda:0')\n",
      "\n",
      "Time cost = 38.946577s\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.9%, Avg loss: 0.543757 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7556, 0.6820], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.679989 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6000], device='cuda:0')\n",
      "\n",
      "Time cost = 39.483723s\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.6%, Avg loss: 0.542994 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7738, 0.6704], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.695052 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6667], device='cuda:0')\n",
      "\n",
      "Time cost = 40.044225s\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.7%, Avg loss: 0.542883 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7577, 0.6774], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.693241 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6667], device='cuda:0')\n",
      "\n",
      "Time cost = 40.616958s\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 67.3%, Avg loss: 0.567778 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7128, 0.6506], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.652919 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 41.181892s\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.1%, Avg loss: 0.529410 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7863, 0.6849], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.674545 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5093, 0.7500], device='cuda:0')\n",
      "\n",
      "Time cost = 41.888941s\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.3%, Avg loss: 0.546113 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7487, 0.6760], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.681311 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5048, 0.6667], device='cuda:0')\n",
      "\n",
      "Time cost = 42.518496s\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 68.8%, Avg loss: 0.544578 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7264, 0.6652], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 54.2%, Avg loss: 0.715402 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5135, 0.8889], device='cuda:0')\n",
      "\n",
      "Time cost = 43.108095s\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.8%, Avg loss: 0.520473 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7772, 0.6846], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.739112 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.8333], device='cuda:0')\n",
      "\n",
      "Time cost = 43.669619s\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.0%, Avg loss: 0.528150 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7441, 0.6887], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.708393 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5044, 0.8571], device='cuda:0')\n",
      "\n",
      "Time cost = 44.226130s\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.6%, Avg loss: 0.542155 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7544, 0.6775], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.688131 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5094, 0.7143], device='cuda:0')\n",
      "\n",
      "Time cost = 44.778467s\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.9%, Avg loss: 0.521207 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7482, 0.6853], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.679218 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5048, 0.6667], device='cuda:0')\n",
      "\n",
      "Time cost = 45.349148s\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.6%, Avg loss: 0.553489 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7354, 0.6862], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.683819 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5096, 0.6875], device='cuda:0')\n",
      "\n",
      "Time cost = 45.924889s\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.3%, Avg loss: 0.528394 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7792, 0.6912], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.685211 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4947, 0.5600], device='cuda:0')\n",
      "\n",
      "Time cost = 46.523256s\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.6%, Avg loss: 0.547043 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7506, 0.6790], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.703848 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.6250], device='cuda:0')\n",
      "\n",
      "Time cost = 47.091274s\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.9%, Avg loss: 0.520467 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7681, 0.6895], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 55.0%, Avg loss: 0.704605 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5196, 0.7222], device='cuda:0')\n",
      "\n",
      "Time cost = 47.746942s\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.9%, Avg loss: 0.526270 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7482, 0.6853], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.673387 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5052, 0.6087], device='cuda:0')\n",
      "\n",
      "Time cost = 48.410170s\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.5%, Avg loss: 0.519647 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7721, 0.6967], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.679746 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 48.988416s\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.1%, Avg loss: 0.534587 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7518, 0.6863], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.683019 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5100, 0.6500], device='cuda:0')\n",
      "\n",
      "Time cost = 49.571858s\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.3%, Avg loss: 0.526689 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7696, 0.6952], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.683331 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 50.133928s\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.3%, Avg loss: 0.520441 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7535, 0.7031], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.711446 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5050, 0.6316], device='cuda:0')\n",
      "\n",
      "Time cost = 50.726425s\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.8%, Avg loss: 0.524536 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7366, 0.6884], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.694373 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5050, 0.6316], device='cuda:0')\n",
      "\n",
      "Time cost = 51.369914s\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.3%, Avg loss: 0.520202 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7613, 0.6977], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 50.8%, Avg loss: 0.694072 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4949, 0.5714], device='cuda:0')\n",
      "\n",
      "Time cost = 52.007636s\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 69.7%, Avg loss: 0.538794 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7286, 0.6774], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.679063 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5052, 0.6087], device='cuda:0')\n",
      "\n",
      "Time cost = 52.585460s\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.4%, Avg loss: 0.530616 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7702, 0.6962], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.680970 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 53.133565s\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.6%, Avg loss: 0.510492 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7585, 0.6898], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.728682 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5096, 0.6875], device='cuda:0')\n",
      "\n",
      "Time cost = 53.816626s\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.4%, Avg loss: 0.534170 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7386, 0.6819], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.698702 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 54.520980s\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 73.6%, Avg loss: 0.503705 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8031, 0.6991], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.678547 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5054, 0.5926], device='cuda:0')\n",
      "\n",
      "Time cost = 55.105418s\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.6%, Avg loss: 0.520301 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7356, 0.7019], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 55.8%, Avg loss: 0.667401 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5281, 0.6452], device='cuda:0')\n",
      "\n",
      "Time cost = 55.684805s\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.1%, Avg loss: 0.536915 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7269, 0.6838], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.665378 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5106, 0.6154], device='cuda:0')\n",
      "\n",
      "Time cost = 56.343796s\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.3%, Avg loss: 0.506721 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7543, 0.6878], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.682264 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5104, 0.6250], device='cuda:0')\n",
      "\n",
      "Time cost = 57.060879s\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.7%, Avg loss: 0.512981 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7692, 0.7006], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.668109 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5104, 0.6250], device='cuda:0')\n",
      "\n",
      "Time cost = 57.755767s\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.7%, Avg loss: 0.525264 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7759, 0.6976], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.3%, Avg loss: 0.701254 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5096, 0.6875], device='cuda:0')\n",
      "\n",
      "Time cost = 58.362304s\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 74.6%, Avg loss: 0.501354 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7976, 0.7139], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.691070 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 58.942572s\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 69.7%, Avg loss: 0.517136 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7319, 0.6758], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 52.5%, Avg loss: 0.678352 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5052, 0.6087], device='cuda:0')\n",
      "\n",
      "Time cost = 59.565532s\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 71.0%, Avg loss: 0.519868 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7655, 0.6793], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.688800 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 60.238511s\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 74.1%, Avg loss: 0.513726 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7995, 0.7067], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.7%, Avg loss: 0.697451 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5000, 0.5909], device='cuda:0')\n",
      "\n",
      "Time cost = 60.893015s\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 72.5%, Avg loss: 0.520663 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7681, 0.6985], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 55.0%, Avg loss: 0.652553 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.5213, 0.6538], device='cuda:0')\n",
      "\n",
      "Time cost = 61.453059s\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 计时\n",
    "time_start = time.time()\n",
    "\n",
    "# writer = SummaryWriter(para.tensor_board_log_dir)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# to device\n",
    "loss_fn = loss_fn.to(device=para.device)\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para.lr)\n",
    "\n",
    "epochs = para.epochs\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    model.train()\n",
    "    accuracy_train, loss_train, precision_train = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    model.eval()\n",
    "    accuracy_cv, loss_cv, precision_cv = test_loop(cv_dataloader, model, loss_fn)\n",
    "\n",
    "    # accuracy2 = test_loop(temp2_dataloader, model, loss_fn)\n",
    "    # print('#')\n",
    "    # accuracy1 = test_loop(temp1_dataloader, model, loss_fn)\n",
    "    # accuracy0 = test_loop(temp0_dataloader, model, loss_fn)\n",
    "\n",
    "    # 写入 tensorboard\n",
    "    if para.classification == 2:\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/cv',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_cv,\n",
    "                               'precision0': precision_cv[0],\n",
    "                               'precision1': precision_cv[1]},\n",
    "                           global_step=t)\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/train',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_train,\n",
    "                               'precision0': precision_train[0],\n",
    "                               'precision1': precision_train[1]},\n",
    "                           global_step=t)\n",
    "\n",
    "    elif para.classification == 3:\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/cv',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_cv,\n",
    "                               'precision0': precision_cv[0],\n",
    "                               'precision1': precision_cv[1],\n",
    "                               'precision2': precision_cv[2]},\n",
    "                           global_step=t)\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/train',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_train,\n",
    "                               'precision0': precision_train[0],\n",
    "                               'precision1': precision_train[1],\n",
    "                               'precision2': precision_train[2]},\n",
    "                           global_step=t)\n",
    "\n",
    "    elif para.classification == 5:\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/cv',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_cv,\n",
    "                               'precision0': precision_cv[0],\n",
    "                               'precision1': precision_cv[1],\n",
    "                               'precision2': precision_cv[2],\n",
    "                               'precision3': precision_cv[3],\n",
    "                               'precision4': precision_cv[4]},\n",
    "                           global_step=t)\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/train',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_train,\n",
    "                               'precision0': precision_train[0],\n",
    "                               'precision1': precision_train[1],\n",
    "                               'precision2': precision_train[2],\n",
    "                               'precision3': precision_train[3],\n",
    "                               'precision4': precision_train[4]},\n",
    "                           global_step=t)\n",
    "\n",
    "    writer.add_scalars(main_tag=para.info_str+'_loss/cv',\n",
    "                       tag_scalar_dict={\n",
    "                           'loss': loss_cv},\n",
    "                       global_step=t)\n",
    "\n",
    "    writer.add_scalars(main_tag=para.info_str+'_loss/train',\n",
    "                       tag_scalar_dict={\n",
    "                           'loss': loss_train},\n",
    "                       global_step=t)\n",
    "    writer.flush()\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('Time cost = %fs' % (time_end - time_start))\n",
    "    print()\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 保存模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish save model!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), para.save_model_path)\n",
    "\n",
    "print('Finish save model!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # captum\n",
    "# from captum.attr import IntegratedGradients\n",
    "#\n",
    "# ig = IntegratedGradients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# temp = cv_dataloader.dataset.tensors[0]\n",
    "# temp.requires_grad_()\n",
    "# attr, delta = ig.attribute(temp,target=1, return_convergence_delta=True)\n",
    "# attr = attr.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Helper method to print importances and visualize distribution\n",
    "# def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
    "#     print(title)\n",
    "#     for i in range(len(feature_names)):\n",
    "#         print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
    "#     y_pos = (np.arange(len(feature_names)))\n",
    "#     if plot:\n",
    "#         plt.figure(figsize=(20,6))\n",
    "#         plt.barh(y_pos, importances, align='center')\n",
    "#         plt.yticks(y_pos, feature_names)\n",
    "#         plt.ylabel(axis_title)\n",
    "#         plt.grid(axis='y')\n",
    "#         plt.title(title)\n",
    "# visualize_importances(feature_names=X_cv.columns.values.tolist(), importances=np.mean(attr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_cv.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.Tensor(\n",
    "#     [[-0.0441,  0.0773],\n",
    "#     [-0.0781, -0.1772],\n",
    "#     [-0.1319, -0.0432],\n",
    "#     [-0.0714, -0.1261],\n",
    "#     [-0.0806, -0.1370],\n",
    "#     [-0.1730, -0.1472],\n",
    "#     [-0.0350, -0.0507],\n",
    "#     [-0.1149, -0.2248]])\n",
    "# # input = input.reshape(-1,4)\n",
    "# target = torch.Tensor([0, 1, 1, 0, 0, 0, 0, 0]).type(torch.LongTensor)\n",
    "# print(input.dtype)\n",
    "# print(target.dtype)\n",
    "# output = loss(input, target)\n",
    "# print(input, target, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Example of target with class indices\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.Tensor([1,4,1]).type(torch.LongTensor)\n",
    "# output = loss(input, target)\n",
    "# print(input,target,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss = nn.BCEWithLogitsLoss()\n",
    "# input = torch.Tensor([0.5, 0.4, 0.3])\n",
    "# target = torch.Tensor([0])\n",
    "# output = loss(input, target)\n",
    "# print(input, target, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}